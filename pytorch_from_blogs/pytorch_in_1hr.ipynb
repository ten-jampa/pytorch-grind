{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ten-jampa/pytorch-grind/blob/main/pytorch_from_blogs/pytorch_in_1hr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d37f94",
      "metadata": {
        "id": "f7d37f94"
      },
      "source": [
        "# Pytorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs\n",
        "Following [blogpost](https://sebastianraschka.com/blog/2023/pytorch-in-one-hour.html) by Sebastian Raschka"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04aa069b",
      "metadata": {
        "id": "04aa069b"
      },
      "source": [
        "## 1. What is PyTorch\n",
        "\n",
        "Pytorch is an open-source Python-based deep learning library that has been growing in scope in both academic research and industrial dev Ops. One of the reasons why PyTorch is so popular is its user-friendly interface and efficiency. However, despite is accessibility, it doesn't compromise on flexibitliy, providing advanced users the ability to tweak lower-level aspects of their models for customization and optimization.\n",
        "\n",
        "### 1.1 The three core componenets of Pytorch\n",
        "\n",
        "There are three broad components for Pytorch:\n",
        "\n",
        "1. Tensor Library - that extends the concept of array-oriented programming (NumPy library) with features for accelerated computation on GPUs.\n",
        "2. Automatic Differentiation Engine - autograd, which enables the automatic computation of gradients for tensor operations, simplyfying backpropagation and model optimization.\n",
        "3. Deep Learning Library - offers modular, flexible, and efficient building blocks (pre-trained models, neurons, loss functions, and optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ffeec8b",
      "metadata": {
        "id": "9ffeec8b"
      },
      "source": [
        "### 1.2 Installing PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "757931fa",
      "metadata": {
        "id": "757931fa",
        "outputId": "8c3bc92b-4e07-41bc-c6c3-54ea90ee2718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m838.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b1db81c0",
      "metadata": {
        "id": "b1db81c0",
        "outputId": "ef375d11-e460-4bb9-d2be-2cf2f263a515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.4.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "## Importing Pytorch\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "59e4fbfb",
      "metadata": {
        "id": "59e4fbfb",
        "outputId": "96e3a093-fd12-4ce5-c2b3-3c99eb1f779a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# check if NVIDIA GPU is available\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194bd4fa",
      "metadata": {
        "id": "194bd4fa"
      },
      "source": [
        "## 2. Understanding Tensors\n",
        "\n",
        "Tensors represent a mathematical concept that generalizes vectors and matrices to potentially higher dimensions. In other words, tensors are mathematical objects that can be characterized by their order (or rank), which provides the number of dimensions. For example, a scalar (just a number) is a tensor of rank 0, a vector is a tensor of rank 1, and a matrix is a tensor of rank 2.\n",
        "\n",
        "From a computational perspective, tensors serve as data containers. For instance, they hold multi-dimensional data, where each dimension represents a different feature. Tensor libraries, such as PyTorch, can create, manipulate, and compute with these multi-dimensional arrays efficiently. In this context, a tensor library functions as an array library.\n",
        "\n",
        "PyTorch tensors are similar to NumPy arrays but have several additional features important for deep learning. For example, PyTorch adds an automatic differentiation engine, simplifying computing gradients, as discussed later in section 2.4. PyTorch tensors also support GPU computations to speed up deep neural network training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d666757b",
      "metadata": {
        "id": "d666757b"
      },
      "source": [
        "### 2.1 Scalars, vectors, matrices, and Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9b20c120",
      "metadata": {
        "id": "9b20c120"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "# create a 0d tensor (scalar)\n",
        "tensor0d = torch.tensor(0)\n",
        "\n",
        "# create a 1d tensor (vector)\n",
        "tensor1d = torch.tensor([1,2,3])\n",
        "\n",
        "# create a 2d tensor (matrix)\n",
        "tensor2d = torch.tensor([[1,2],[3,4]])\n",
        "\n",
        "# create a 3d tensor (from a nested python list)\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "\n",
        "# rank of tensor is len(tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20bb2ea3",
      "metadata": {
        "id": "20bb2ea3"
      },
      "source": [
        "### 2.2 Tensor data types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b687e6cf",
      "metadata": {
        "id": "b687e6cf",
        "outputId": "db1d3a14-b51c-4f74-955f-9cfaf1ff57af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "tensor1d = torch.tensor([1,2,3])\n",
        "\n",
        "print(tensor1d.dtype) # default 64-bit integer data type from python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e303f088",
      "metadata": {
        "id": "e303f088",
        "outputId": "227a9630-34b8-4024-8cf2-aa1e66728b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# we can create tensor from python float with 32-bit precision\n",
        "\n",
        "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(floatvec.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d2eebea1",
      "metadata": {
        "id": "d2eebea1",
        "outputId": "49904bad-5080-48d0-dae0-d8b5bb828905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n"
          ]
        }
      ],
      "source": [
        "# it is easy to change the precision\n",
        "\n",
        "floatvec = tensor1d.to(torch.float32)\n",
        "print(floatvec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7419922",
      "metadata": {
        "id": "c7419922"
      },
      "source": [
        "### 2.3 Common PyTorch tensor operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "761422e1",
      "metadata": {
        "id": "761422e1",
        "outputId": "d5536294-fc56-4903-8b64-5fe5041b6d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tensor2d = torch.tensor(\n",
        "    [\n",
        "        [1,2,3],\n",
        "        [4,5,6]\n",
        "    ]\n",
        ")\n",
        "tensor2d.shape # prints the shape attribute of thetensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "68708006",
      "metadata": {
        "id": "68708006",
        "outputId": "1660de36-1873-457d-e17e-07afbdac0634",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# to reshape the tensor\n",
        "tensor2d.reshape(3,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d03752b9",
      "metadata": {
        "id": "d03752b9",
        "outputId": "2fa45cf8-610e-4cbc-f006-2cc55664ee22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# more common way to reshape is the view() method\n",
        "tensor2d.view(3,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a0a0cd63",
      "metadata": {
        "id": "a0a0cd63",
        "outputId": "b0bc6d9f-7bd7-42de-c5a6-93480bfe02ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tensor2d #the methods above haven't changed the original tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2fe91041",
      "metadata": {
        "id": "2fe91041",
        "outputId": "fda74986-23f1-4524-9c70-d9890e817d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4],\n",
              "        [2, 5],\n",
              "        [3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# transpose a tensor which means flipping it across its diagonal\n",
        "\n",
        "tensor2d.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7286ac04",
      "metadata": {
        "id": "7286ac04",
        "outputId": "fb0f6614-9f78-4ce5-8b7c-6380a706ed7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-1277073988.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3697.)\n",
            "  tensor3d.T # you can also transpose a tensor of rank 3 and more but it's harder to visualize what's going on\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 5],\n",
              "         [3, 7]],\n",
              "\n",
              "        [[2, 6],\n",
              "         [4, 8]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "tensor3d.T # you can also transpose a tensor of rank 3 and more but it's harder to visualize what's going on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6e4ec89f",
      "metadata": {
        "id": "6e4ec89f",
        "outputId": "3d001997-56ef-4b8c-91f0-aadd5061ae21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# common way to multiply two matrices matmul method\n",
        "tensor2d.matmul(tensor2d.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "849c0dfe",
      "metadata": {
        "id": "849c0dfe",
        "outputId": "5578992d-8b68-4279-945e-54ecaa895db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14, 32],\n",
              "        [32, 77]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# more common way, which achieves the same thing more compactly.\n",
        "\n",
        "tensor2d @ tensor2d.T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce3eab19",
      "metadata": {
        "id": "ce3eab19"
      },
      "source": [
        "## 3. Seeing models as computation graphs\n",
        "\n",
        "PyTorch’s autograd system provides functions to compute gradients in dynamic computational graphs automatically.\n",
        "\n",
        "A computational graph is a directed graph that allows us to express and visualize mathematical expressions. Inthe context of deep learning, a computation graph lays out the sequence of calculations needed to compute the output of a neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "29b581a1",
      "metadata": {
        "id": "29b581a1",
        "outputId": "42fdc877-ab1d-48d4-ac0f-ac7d54145e61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0852)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])  # true label\n",
        "x1 = torch.tensor([1.1]) # input feature\n",
        "w1 = torch.tensor([2.2]) # weight parameter\n",
        "b = torch.tensor([0.0])  # bias unit\n",
        "\n",
        "z = x1 * w1 + b          # net input\n",
        "a = torch.sigmoid(z)     # activation & output\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "170f1a20",
      "metadata": {
        "id": "170f1a20"
      },
      "source": [
        "The computational graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bc21e71f",
      "metadata": {
        "id": "bc21e71f",
        "outputId": "56ce5d79-a149-4236-f291-25eb8354a0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_07.webp\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Display an image from the blogpost\n",
        "display(Image(url=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_07.webp\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c1a1821",
      "metadata": {
        "id": "4c1a1821"
      },
      "source": [
        "## 4. Automatic Differentiaiton made easy\n",
        "\n",
        "PyTorch builds computation graphs by default if one of its terminal nodes has the ```requires_grad``` attribute set to True. This is useful if we want to compute gradients. Gradients are required when training neural networks via the popular backpropagation algorithm, which can be thought of as an implementation of the chain rule from calculus for neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "31f35321",
      "metadata": {
        "id": "31f35321",
        "outputId": "11b3e370-efe9-4f42-f4d4-236d99dbb36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_08.webp\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# display an image\n",
        "display(Image(url = \"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_08.webp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "20a2cb50",
      "metadata": {
        "id": "20a2cb50"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4e525d6b",
      "metadata": {
        "id": "4e525d6b",
        "outputId": "54e73744-5d4b-4783-93ae-8311c7e3ffe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n"
          ]
        }
      ],
      "source": [
        "print(grad_L_w1)\n",
        "print(grad_L_b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6987c839",
      "metadata": {
        "id": "6987c839",
        "outputId": "99b53dc8-c0f0-4130-8480-fe6d02cca821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ],
      "source": [
        "# we computed the gradients manually but we can call the native backward\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73e4c4c",
      "metadata": {
        "id": "e73e4c4c"
      },
      "source": [
        "## 5. Implementing Multilayer Neural Networks\n",
        "\n",
        "When implementing a neural network in PyTorch, we typically subclass the ```torch.nn.Module``` class to define our own custom network architecture. This ```Module``` base class provides a lot of functionality, making it easier to build and train models. For instance, it allows us to encapsulate layers and operations and keep track of the model’s parameters.\n",
        "\n",
        "Within this subclass, we define the network layers in the ```__init__``` constructor and specify how they interact in the ```forward``` method. The ```forward``` method describes how the input data passes through the network and comes together as a computation graph.\n",
        "\n",
        "In contrast, the backward method, which we typically do not need to implement ourselves, is used during training to compute gradients of the loss function with respect to the model parameters, as we will see in Section 2.7, A typical training loop.\n",
        "\n",
        "The following code implements a classic multilayer perceptron with two hidden layers to illustrate a typical usage of the ```Module``` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "51b940d8",
      "metadata": {
        "id": "51b940d8"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            # 1st layer\n",
        "            torch.nn.Linear(num_inputs, 30), # 30 hidden units node\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd Layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1c76614e",
      "metadata": {
        "id": "1c76614e",
        "outputId": "9d657ec4-07e4-45ae-b647-13a3c87588f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44e0ddcb",
      "metadata": {
        "id": "44e0ddcb"
      },
      "source": [
        "Note that we used the ```Sequential``` class when we implemented the ```NeuralNetwork``` class. Using ```Sequential``` is not required, but it can make our life easier if we have a series of layers that we want to execute in a specific order, as is the case here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "d434771c",
      "metadata": {
        "id": "d434771c",
        "outputId": "9bb8a568-1e6f-47ca-bae0-17f3fd01d55d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters:  2213\n"
          ]
        }
      ],
      "source": [
        "# total number of trainable parameters of this model\n",
        "\n",
        "num_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad\n",
        ")\n",
        "\n",
        "print('Total number of trainable model parameters: ', num_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecd510a",
      "metadata": {
        "id": "4ecd510a"
      },
      "source": [
        "In the case of our neural network model with the two hidden layers above, these trainable parameters are contained in the ```torch.nn.Linear``` layers. A linear layer multiples the inputs with a wieght matrix and adds a bias vector. THis is sometimes also referred to as a feedforward or fully connected layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b1a7e33f",
      "metadata": {
        "id": "b1a7e33f",
        "outputId": "b4270b56-b851-4bb3-efd6-c089df7f4eea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=20, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MZPFKMlQDi8k",
        "outputId": "e491db70-d324-4b2e-9cc7-e4008118b32e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1136, -0.0423, -0.0922,  ..., -0.0141, -0.0605,  0.0980],\n",
            "        [-0.0966, -0.0946, -0.0097,  ...,  0.0683,  0.1382, -0.0259],\n",
            "        [-0.0043,  0.1131,  0.0089,  ...,  0.0789, -0.1252, -0.0931],\n",
            "        ...,\n",
            "        [-0.0827,  0.0314,  0.0436,  ...,  0.0404, -0.1295,  0.0118],\n",
            "        [ 0.0867,  0.0217,  0.1398,  ..., -0.0560, -0.1069,  0.1034],\n",
            "        [-0.0395,  0.0778,  0.1309,  ...,  0.0416,  0.0698,  0.1371]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# we can print the weights of each layer\n",
        "\n",
        "print(model.layers[0].weight)"
      ],
      "id": "MZPFKMlQDi8k"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6cf0685d",
      "metadata": {
        "id": "6cf0685d",
        "outputId": "077992fa-3866-4888-be54-6affb22f9d85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 50])\n"
          ]
        }
      ],
      "source": [
        "# to get the shape of the large weights matrix\n",
        "\n",
        "print(model.layers[0].weight.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "dbf0bc76",
      "metadata": {
        "id": "dbf0bc76",
        "outputId": "7b68da65-4c7e-4037-fa34-fe33cb3b429c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([-0.0755,  0.0843, -0.0975,  0.0156, -0.1404,  0.1349, -0.0643, -0.0745,\n",
            "        -0.0517,  0.0967, -0.0285, -0.1308,  0.0306,  0.0543,  0.1243, -0.1403,\n",
            "        -0.0986, -0.0761, -0.0456,  0.0312,  0.0408, -0.0600,  0.1393,  0.0653,\n",
            "        -0.0293, -0.0007, -0.0749,  0.1156, -0.0832, -0.0652],\n",
            "       requires_grad=True)\n",
            "torch.Size([30])\n"
          ]
        }
      ],
      "source": [
        "# we can get the bias vector\n",
        "\n",
        "print(model.layers[0].bias)\n",
        "print(model.layers[0].bias.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3905151c",
      "metadata": {
        "id": "3905151c",
        "outputId": "ed164abc-9439-4d45-86b7-f093dc4d879a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665, 0.1366, 0.1025, 0.1841,\n",
            "         0.7264, 0.3153, 0.6871, 0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274,\n",
            "         0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826, 0.2745, 0.6584, 0.2775,\n",
            "         0.8573, 0.8993, 0.0390, 0.9268, 0.7388, 0.7179, 0.7058, 0.9156, 0.4340,\n",
            "         0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318, 0.4545, 0.9737, 0.4606,\n",
            "         0.5159, 0.4220, 0.5786, 0.9455, 0.8057]])\n",
            "tensor([[0.1446, 0.0256, 0.2507]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([1, 3])\n"
          ]
        }
      ],
      "source": [
        "# forward pass\n",
        "torch.manual_seed(123)\n",
        "\n",
        "X = torch.rand((1, 50))\n",
        "print(X)# note the shape, this is a row vector\n",
        "out = model(X)\n",
        "print(out)\n",
        "print(out.shape) #another row vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9bf8193",
      "metadata": {
        "id": "b9bf8193"
      },
      "source": [
        "Here, grad_fn=<AddmmBackward0> represents the last-used function to compute a variable in the computational graph. In particular, grad_fn=<AddmmBackward0> means that the tensor we are inspecting was created via a matrix multiplication and addition operation. PyTorch will use this information when it computes gradients during backpropagation. The <AddmmBackward0> part of grad_fn=<AddmmBackward0> specifies the operation that was performed. In this case, it is an Addmm operation. Addmm stands for matrix multiplication (mm) followed by an addition (Add).\n",
        "\n",
        "If we just want to use a network without training or backpropagation, for example, if we use it for prediction after training, constructing this computational graph for backpropagation can be wasteful as it performs unnecessary computations and consumes additional memory. So, when we use a model for inference (for instance, making predictions) rather than training, it is a best practice to use the torch.no_grad() context manager, as shown below. This tells PyTorch that it doesn’t need to keep track of the gradients, which can result in significant savings in memory and computation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1123f4fd",
      "metadata": {
        "id": "1123f4fd",
        "outputId": "a30562a0-6256-406d-92d1-c8eaa7b2c8af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1780, 0.0409, 0.2768],\n",
            "        [0.1568, 0.0643, 0.2248],\n",
            "        [0.1621, 0.0524, 0.2411],\n",
            "        [0.1547, 0.0537, 0.2410],\n",
            "        [0.1406, 0.0730, 0.2086],\n",
            "        [0.1495, 0.0386, 0.2437],\n",
            "        [0.1804, 0.0594, 0.2459],\n",
            "        [0.1551, 0.0822, 0.1894],\n",
            "        [0.1605, 0.0519, 0.2508],\n",
            "        [0.1410, 0.0543, 0.2469]])\n",
            "torch.Size([10, 3])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    # don't keep the compute graph in memory\n",
        "    X_tens = torch.rand((10, 50))\n",
        "    out = model(X_tens)\n",
        "    print(out)\n",
        "    print(out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee15b64d",
      "metadata": {
        "id": "ee15b64d"
      },
      "source": [
        "## 6. Setting up Efficient data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "59083f9a",
      "metadata": {
        "id": "59083f9a",
        "outputId": "db3697bf-4fae-40bf-d6ce-c99135d2ddaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_10.webp\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# overall idea behind data loading in Pytorch\n",
        "\n",
        "display(Image(url = 'https://sebastianraschka.com/images/teaching/pytorch-1h/figure_10.webp'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f64500bb",
      "metadata": {
        "id": "f64500bb"
      },
      "source": [
        "Pytorch implements a ```Dataset``` and ```DataLoader``` class. The Dataset class is used to instantiate objects that define how each data record is loaded. The Dataloader handles how the data is shuffled and assembled into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "57113e9b",
      "metadata": {
        "id": "57113e9b"
      },
      "outputs": [],
      "source": [
        "# code to create a dataset\n",
        "\n",
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "91c910ca",
      "metadata": {
        "id": "91c910ca"
      },
      "outputs": [],
      "source": [
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "583cbdcd",
      "metadata": {
        "id": "583cbdcd"
      },
      "outputs": [],
      "source": [
        "# we create a custom dataset class.\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e40843a3",
      "metadata": {
        "id": "e40843a3"
      },
      "outputs": [],
      "source": [
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9b909dad",
      "metadata": {
        "id": "9b909dad"
      },
      "outputs": [],
      "source": [
        "# we can use Pytorch DataLoader class to sample from it\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset = train_ds,\n",
        "    batch_size= 2,\n",
        "    shuffle=True,\n",
        "    num_workers =0 # what's this argument? # parallelism used\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "31e7d907",
      "metadata": {
        "id": "31e7d907"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0b4b0e22",
      "metadata": {
        "id": "0b4b0e22",
        "outputId": "8b2b783a-62bc-4f2b-9d11-0fb0ac578f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:  tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2:  tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 3:  tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ],
      "source": [
        "# iteration over Dataloader works quite similarly\n",
        "\n",
        "for idx, (X, y) in enumerate(train_loader):\n",
        "    print(f'Batch {idx + 1}: ', X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "bf893f35",
      "metadata": {
        "id": "bf893f35",
        "outputId": "32f71c05-7a26-4ab8-8a4b-8f7ad46519b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:  tensor([[-1.2000,  3.1000],\n",
            "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
            "Batch 2:  tensor([[ 2.3000, -1.1000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 3:  tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
          ]
        }
      ],
      "source": [
        "# second iter is not the same for the DNN to have a different sequence of learning\n",
        "\n",
        "for idx, (X, y) in enumerate(train_loader):\n",
        "    print(f'Batch {idx + 1}: ', X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a5b26d67",
      "metadata": {
        "id": "a5b26d67"
      },
      "outputs": [],
      "source": [
        "# we see that the last batch can have mismatching data samples given the unevenness of data\n",
        "# entries to batch_size, therefore it's recommended to drop the last batch\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle= True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a419c419",
      "metadata": {
        "id": "a419c419",
        "outputId": "faf063f4-b547-4c8a-9803-66af1c7b7a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-0.9000,  2.9000],\n",
            "        [ 2.3000, -1.1000]]) tensor([0, 1])\n",
            "Batch 2: tensor([[ 2.7000, -1.5000],\n",
            "        [-0.5000,  2.6000]]) tensor([1, 0])\n"
          ]
        }
      ],
      "source": [
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a07b08f",
      "metadata": {
        "id": "5a07b08f"
      },
      "source": [
        "## 7. A Typical Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b138f9c1",
      "metadata": {
        "id": "b138f9c1",
        "outputId": "ee9863b2-af12-4d96-81d7-8597020936f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n",
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2) # instantiating the model\n",
        "print(model)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5) # instantiating the optimizer we are using\n",
        "\n",
        "num_epochs = 3 # no of training over the full batch that we are doing\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train() # set in training mode\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels) # Loss function\n",
        "\n",
        "        optimizer.zero_grad() # clean the previous results\n",
        "        loss.backward() # compute the gradients\n",
        "        optimizer.step() # use the optimizer to step along the gradients\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval() # eval mode\n",
        "    # Optional model evaluation\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_train)\n",
        "\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "800cffb7",
      "metadata": {
        "id": "800cffb7",
        "outputId": "92d07aae-e453-4817-f03e-0362eaba69c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False) #what's scimode? (just print formatting I guess)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4e2364aa",
      "metadata": {
        "id": "4e2364aa",
        "outputId": "d4086553-f589-4efb-db61-df1fd967117a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "predictions = torch.argmax(probas, dim = 1) #find the max index along each dim 1 (which is the col dimension)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "90167b53",
      "metadata": {
        "id": "90167b53",
        "outputId": "93c6300d-68ad-49a2-e688-fa91e0ee9490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "predictions = torch.argmax(outputs, dim=1)\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bb16ac76",
      "metadata": {
        "id": "bb16ac76",
        "outputId": "9d7239e3-d952-4e5f-b665-50d7cc61a7d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "predictions == y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "15e09b9d",
      "metadata": {
        "id": "15e09b9d",
        "outputId": "9590ce11-6fd8-437c-a512-7d35e538b0fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# using torch.sum, we can count the number of correct predictions as follows:\n",
        "\n",
        "torch.sum(predictions == y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "77c3e6a1",
      "metadata": {
        "id": "77c3e6a1"
      },
      "outputs": [],
      "source": [
        "# To generalize the computationa of the prediciton accuracy, we implement\n",
        "\n",
        "def compute_accuracy(model, train_loader):\n",
        "\n",
        "    # set in eval model\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0.0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(train_loader):\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim = 1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item() #getting the values from the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "08bbff7e",
      "metadata": {
        "id": "08bbff7e"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy = compute_accuracy(model, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "f18c7ed7",
      "metadata": {
        "id": "f18c7ed7",
        "outputId": "3abcf641-3308-49bc-c727-7fb9eca14266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d14de5",
      "metadata": {
        "id": "f9d14de5"
      },
      "source": [
        "## 8. Saving and Loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "b1594802",
      "metadata": {
        "id": "b1594802"
      },
      "outputs": [],
      "source": [
        "# The recommended way to save and load models in PyTorch\n",
        "\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "4bec0d74",
      "metadata": {
        "id": "4bec0d74"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(),  'model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a1021b1",
      "metadata": {
        "id": "1a1021b1"
      },
      "source": [
        "The model's ```state_dict``` is a Python dictionary object that maps each layer in the model to its trainable parameters (weights and biases). Note that \"model.pth\" is an arbitrary filename for the model file saved to disk. We can give it any name and file ending we like; however, .pth and .pt are the most common conventions.\n",
        "\n",
        "Once we saved the model, we can restore it from disk as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "db20491c",
      "metadata": {
        "id": "db20491c",
        "outputId": "0ebab13a-9918-4826-d3c6-fcc5c93242d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
        "model.load_state_dict(torch.load('model.pth', weights_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "5b8929ca",
      "metadata": {
        "id": "5b8929ca",
        "outputId": "9f673386-8c48-434f-c77b-6e27e6185c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model2 = NeuralNetwork(2,2)\n",
        "model2.load_state_dict(torch.load('model.pkl', weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Optimizing training performance with GPUs\n",
        "\n",
        "### 9.1 PyTorch computations on GPU devices\n",
        "\n",
        "Modyifyng the training loop above to optionally run on a GPU is relatively simple and only requires changing three lines of code.\n",
        "Before we make the modifications, it’s crucial to understand the main concept behind GPU computations within PyTorch.\n",
        "\n",
        "First, we need to introduce the notion of devices. In PyTorch, a device is where computations occur, and data resides. The CPU and the GPU are examples of devices. A PyTorch tensor resides in a device, and its operations are executed on the same device.\n",
        "\n",
        "Let’s see how this works in action. Assuming that you installed a GPU-compatible version of PyTorch as explained in section 2.1.3, Installing PyTorch, we can double-check that our runtime indeed supports GPU computing via the following code:"
      ],
      "metadata": {
        "id": "TKhU2bfdEqNA"
      },
      "id": "TKhU2bfdEqNA"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "014d2cde",
      "metadata": {
        "id": "014d2cde",
        "outputId": "04f9f5b4-6cbb-4ac6-8deb-651027bfba84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by default, the computations run on CPU\n",
        "tensor_1 = torch.tensor([1., 2., 3.])\n",
        "tensor_2 = torch.tensor([4., 5., 6.])\n",
        "\n",
        "print(tensor_1 + tensor_2)\n"
      ],
      "metadata": {
        "id": "Lz1xdQuzFLnU",
        "outputId": "34afd5bf-4e19-45cf-f5b6-c269145a9c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Lz1xdQuzFLnU",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = tensor_1.to(\"cuda\") # transfer these tensors onto a GPU and perform the addition there\n",
        "tensor_2 = tensor_2.to(\"cuda\")\n",
        "\n",
        "print(tensor_1 + tensor_2)\n"
      ],
      "metadata": {
        "id": "TojCoz7qFSUk",
        "outputId": "cf1f328c-9a64-4cb4-95a0-e082c073e0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TojCoz7qFSUk",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the resulting tensor now includes the device information, device='cuda:0', which means that the tensors reside on the first GPU. If your machine hosts multiple GPUs, you have the option to specify which GPU you’d like to transfer the tensors to. You can do this by indicating the device ID in the transfer command. For instance, you can use .to(\"cuda:0\"), .to(\"cuda:1\"), and so on.\n",
        "\n",
        "However, it is important to note that all tensors must be on the same device. Otherwise, the computation will fail, as shown below, where one tensor resides on the CPU and the other on the GPU:"
      ],
      "metadata": {
        "id": "P4baa9xLFwMs"
      },
      "id": "P4baa9xLFwMs"
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = tensor_1.to(\"cuda:1\") # transfer these tensors onto a GPU and perform the addition there\n",
        "tensor_2 = tensor_2.to(\"cuda:1\")\n",
        "\n",
        "print(tensor_1 + tensor_2)\n",
        "\n",
        "# we have only one GPU"
      ],
      "metadata": {
        "id": "zthm42WbFkZI",
        "outputId": "247dd6df-adf8-4678-ef6f-7e186a64ede8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "id": "zthm42WbFkZI",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-64-2893807412.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# transfer these tensors onto a GPU and perform the addition there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtensor_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the tensors have to be on the same device\n",
        "tensor_1 = tensor_1.to(\"cpu\")\n",
        "print(tensor_1 + tensor_2)\n"
      ],
      "metadata": {
        "id": "0fldFVnaFmqD",
        "outputId": "e89daa6b-9e85-426a-8f93-a3ca9f1dfe3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "id": "0fldFVnaFmqD",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-65-2719778381.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the tensors have to be on the same device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtensor_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtensor_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 Single-GPU Training\n"
      ],
      "metadata": {
        "id": "SSzhI2yiGCp2"
      },
      "id": "SSzhI2yiGCp2"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "\n",
        "# New: Define a device variable that defaults to GPU but falls back to cpu if not available\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "# same loop\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.5)\n",
        "\n",
        "num_epochs =  3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "    features, labels = features.to(device), labels.to(device)\n",
        "    logits = model(features)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "    optimizer.zero_grad() # clean gradients from last round\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    ## Logging\n",
        "    print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "                f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "                f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "  model.eval()\n"
      ],
      "metadata": {
        "id": "3CLjj04mF_Cx",
        "outputId": "22378616-c470-455f-d806-6aa4cb10467e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3CLjj04mF_Cx",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zxZ3HtqHK7c"
      },
      "id": "6zxZ3HtqHK7c",
      "execution_count": 71,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}