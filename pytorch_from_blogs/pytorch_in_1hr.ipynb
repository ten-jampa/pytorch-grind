{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d37f94",
   "metadata": {},
   "source": [
    "# Pytorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs\n",
    "Following [blogpost](https://sebastianraschka.com/blog/2023/pytorch-in-one-hour.html) by Sebastian Raschka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa069b",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch\n",
    "\n",
    "Pytorch is an open-source Python-based deep learning library that has been growing in scope in both academic research and industrial dev Ops. One of the reasons why PyTorch is so popular is its user-friendly interface and efficiency. However, despite is accessibility, it doesn't compromise on flexibitliy, providing advanced users the ability to tweak lower-level aspects of their models for customization and optimization. \n",
    "\n",
    "### 1.1 The three core componenets of Pytorch\n",
    "\n",
    "There are three broad components for Pytorch:\n",
    "\n",
    "1. Tensor Library - that extends the concept of array-oriented programming (NumPy library) with features for accelerated computation on GPUs.\n",
    "2. Automatic Differentiation Engine - autograd, which enables the automatic computation of gradients for tensor operations, simplyfying backpropagation and model optimization.\n",
    "3. Deep Learning Library - offers modular, flexible, and efficient building blocks (pre-trained models, neurons, loss functions, and optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffeec8b",
   "metadata": {},
   "source": [
    "### 1.2 Installing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757931fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.4.1\n",
      "  Downloading torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch==2.4.1)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch==2.4.1)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch==2.4.1)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.4.1)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch==2.4.1)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch==2.4.1)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch==2.4.1)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.1)\n",
      "  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.1)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl (797.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [torch]m22/23\u001b[0m [torch]-cusolver-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 setuptools-80.9.0 sympy-1.14.0 torch-2.4.1 triton-3.0.0 typing-extensions-4.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1db81c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/pytorch-grind/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:258: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu121'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing Pytorch\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e4fbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if NVIDIA GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bd4fa",
   "metadata": {},
   "source": [
    "## 2. Understanding Tensors\n",
    "\n",
    "Tensors represent a mathematical concept that generalizes vectors and matrices to potentially higher dimensions. In other words, tensors are mathematical objects that can be characterized by their order (or rank), which provides the number of dimensions. For example, a scalar (just a number) is a tensor of rank 0, a vector is a tensor of rank 1, and a matrix is a tensor of rank 2.\n",
    "\n",
    "From a computational perspective, tensors serve as data containers. For instance, they hold multi-dimensional data, where each dimension represents a different feature. Tensor libraries, such as PyTorch, can create, manipulate, and compute with these multi-dimensional arrays efficiently. In this context, a tensor library functions as an array library.\n",
    "\n",
    "PyTorch tensors are similar to NumPy arrays but have several additional features important for deep learning. For example, PyTorch adds an automatic differentiation engine, simplifying computing gradients, as discussed later in section 2.4. PyTorch tensors also support GPU computations to speed up deep neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666757b",
   "metadata": {},
   "source": [
    "### 2.1 Scalars, vectors, matrices, and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b20c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# create a 0d tensor (scalar)\n",
    "tensor0d = torch.tensor(0)\n",
    "\n",
    "# create a 1d tensor (vector)\n",
    "tensor1d = torch.tensor([1,2,3])\n",
    "\n",
    "# create a 2d tensor (matrix)\n",
    "tensor2d = torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "# create a 3d tensor (from a nested python list)\n",
    "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "# rank of tensor is len(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb2ea3",
   "metadata": {},
   "source": [
    "### 2.2 Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b687e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "tensor1d = torch.tensor([1,2,3])\n",
    "\n",
    "print(tensor1d.dtype) # default 64-bit integer data type from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e303f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# we can create tensor from python float with 32-bit precision\n",
    "\n",
    "floatvec = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(floatvec.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2eebea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# it is easy to change the precision\n",
    "\n",
    "floatvec = tensor1d.to(torch.float32)\n",
    "print(floatvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7419922",
   "metadata": {},
   "source": [
    "### 2.3 Common PyTorch tensor operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761422e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d = torch.tensor(\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6]\n",
    "    ]\n",
    ")\n",
    "tensor2d.shape # prints the shape attribute of thetensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68708006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to reshape the tensor\n",
    "tensor2d.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d03752b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more common way to reshape is the view() method\n",
    "tensor2d.view(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0a0cd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2d #the methods above haven't changed the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fe91041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose a tensor which means flipping it across its diagonal\n",
    "\n",
    "tensor2d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7286ac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 5],\n",
       "         [3, 7]],\n",
       "\n",
       "        [[2, 6],\n",
       "         [4, 8]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d.T # you can also transpose a tensor of rank 3 and more but it's harder to visualize what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e4ec89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common way to multiply two matrices matmul method\n",
    "tensor2d.matmul(tensor2d.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "849c0dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more common way, which achieves the same thing more compactly.\n",
    "\n",
    "tensor2d @ tensor2d.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3eab19",
   "metadata": {},
   "source": [
    "## 3. Seeing models as computation graphs\n",
    "\n",
    "PyTorch’s autograd system provides functions to compute gradients in dynamic computational graphs automatically.\n",
    "\n",
    "A computational graph is a directed graph that allows us to express and visualize mathematical expressions. Inthe context of deep learning, a computation graph lays out the sequence of calculations needed to compute the output of a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29b581a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0852)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y = torch.tensor([1.0])  # true label\n",
    "x1 = torch.tensor([1.1]) # input feature\n",
    "w1 = torch.tensor([2.2]) # weight parameter\n",
    "b = torch.tensor([0.0])  # bias unit\n",
    "\n",
    "z = x1 * w1 + b          # net input\n",
    "a = torch.sigmoid(z)     # activation & output\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f1a20",
   "metadata": {},
   "source": [
    "The computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc21e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_07.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display an image from the blogpost\n",
    "display(Image(url=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_07.webp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a1821",
   "metadata": {},
   "source": [
    "## 4. Automatic Differentiaiton made easy\n",
    "\n",
    "PyTorch builds computation graphs by default if one of its terminal nodes has the ```requires_grad``` attribute set to True. This is useful if we want to compute gradients. Gradients are required when training neural networks via the popular backpropagation algorithm, which can be thought of as an implementation of the chain rule from calculus for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31f35321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_08.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# display an image\n",
    "display(Image(url = \"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_08.webp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20a2cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "\n",
    "y = torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "z = x1 * w1 + b\n",
    "a = torch.sigmoid(z)\n",
    "\n",
    "loss = F.binary_cross_entropy(a, y)\n",
    "\n",
    "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
    "grad_L_b = grad(loss, b, retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e525d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "print(grad_L_w1)\n",
    "print(grad_L_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6987c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0898])\n",
      "tensor([-0.0817])\n"
     ]
    }
   ],
   "source": [
    "# we computed the gradients manually but we can call the native backward\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(w1.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e4c4c",
   "metadata": {},
   "source": [
    "## 5. Implementing Multilayer Neural Networks\n",
    "\n",
    "When implementing a neural network in PyTorch, we typically subclass the ```torch.nn.Module``` class to define our own custom network architecture. This ```Module``` base class provides a lot of functionality, making it easier to build and train models. For instance, it allows us to encapsulate layers and operations and keep track of the model’s parameters.\n",
    "\n",
    "Within this subclass, we define the network layers in the ```__init__``` constructor and specify how they interact in the ```forward``` method. The ```forward``` method describes how the input data passes through the network and comes together as a computation graph.\n",
    "\n",
    "In contrast, the backward method, which we typically do not need to implement ourselves, is used during training to compute gradients of the loss function with respect to the model parameters, as we will see in Section 2.7, A typical training loop.\n",
    "\n",
    "The following code implements a classic multilayer perceptron with two hidden layers to illustrate a typical usage of the ```Module``` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51b940d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # 1st layer\n",
    "            torch.nn.Linear(num_inputs, 30), # 30 hidden units node\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # 2nd Layer\n",
    "            torch.nn.Linear(30, 20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # output layer\n",
    "            torch.nn.Linear(20, num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(50, 3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e0ddcb",
   "metadata": {},
   "source": [
    "Note that we used the ```Sequential``` class when we implemented the ```NeuralNetwork``` class. Using ```Sequential``` is not required, but it can make our life easier if we have a series of layers that we want to execute in a specific order, as is the case here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d434771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable model parameters:  2213\n"
     ]
    }
   ],
   "source": [
    "# total number of trainable parameters of this model \n",
    "\n",
    "num_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print('Total number of trainable model parameters: ', num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd510a",
   "metadata": {},
   "source": [
    "In the case of our neural network model with the two hidden layers above, these trainable parameters are contained in the ```torch.nn.Linear``` layers. A linear layer multiples the inputs with a wieght matrix and adds a bias vector. THis is sometimes also referred to as a feedforward or fully connected layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1a7e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=20, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0528,  0.0123, -0.0532,  ...,  0.0036,  0.1331, -0.0363],\n",
      "        [-0.1081, -0.1389,  0.0892,  ...,  0.0878,  0.0599,  0.1308],\n",
      "        [ 0.0127,  0.0118,  0.0093,  ...,  0.0421,  0.1163, -0.0179],\n",
      "        ...,\n",
      "        [-0.1315,  0.1296, -0.0684,  ..., -0.0139,  0.1108, -0.0915],\n",
      "        [ 0.0965,  0.1301,  0.0184,  ...,  0.1084, -0.0170,  0.0810],\n",
      "        [ 0.0990, -0.0560,  0.0147,  ...,  0.0257, -0.0633,  0.0721]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# we can print the weights of each layer \n",
    "\n",
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cf0685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 50])\n"
     ]
    }
   ],
   "source": [
    "# to get the shape of the large weights matrix\n",
    "\n",
    "print(model.layers[0].weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbf0bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.1008,  0.0554,  0.0752,  0.0556, -0.0464, -0.0586,  0.1040, -0.1344,\n",
      "         0.1136, -0.1119, -0.0690,  0.0902, -0.1227,  0.0597, -0.1199, -0.0397,\n",
      "        -0.1371,  0.0049, -0.0310,  0.0848, -0.0541, -0.0976,  0.1203,  0.0612,\n",
      "         0.1245, -0.0704,  0.0893,  0.1408,  0.0509, -0.1034],\n",
      "       requires_grad=True)\n",
      "torch.Size([30])\n"
     ]
    }
   ],
   "source": [
    "# we can get the bias vector \n",
    "\n",
    "print(model.layers[0].bias)\n",
    "print(model.layers[0].bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3905151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665, 0.1366, 0.1025, 0.1841,\n",
      "         0.7264, 0.3153, 0.6871, 0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274,\n",
      "         0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826, 0.2745, 0.6584, 0.2775,\n",
      "         0.8573, 0.8993, 0.0390, 0.9268, 0.7388, 0.7179, 0.7058, 0.9156, 0.4340,\n",
      "         0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318, 0.4545, 0.9737, 0.4606,\n",
      "         0.5159, 0.4220, 0.5786, 0.9455, 0.8057]])\n",
      "tensor([[ 0.0670, -0.0312,  0.2049]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "torch.manual_seed(123)\n",
    "\n",
    "X = torch.rand((1, 50)) \n",
    "print(X)# note the shape, this is a row vector\n",
    "out = model(X)\n",
    "print(out)\n",
    "print(out.shape) #another row vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf8193",
   "metadata": {},
   "source": [
    "Here, grad_fn=<AddmmBackward0> represents the last-used function to compute a variable in the computational graph. In particular, grad_fn=<AddmmBackward0> means that the tensor we are inspecting was created via a matrix multiplication and addition operation. PyTorch will use this information when it computes gradients during backpropagation. The <AddmmBackward0> part of grad_fn=<AddmmBackward0> specifies the operation that was performed. In this case, it is an Addmm operation. Addmm stands for matrix multiplication (mm) followed by an addition (Add).\n",
    "\n",
    "If we just want to use a network without training or backpropagation, for example, if we use it for prediction after training, constructing this computational graph for backpropagation can be wasteful as it performs unnecessary computations and consumes additional memory. So, when we use a model for inference (for instance, making predictions) rather than training, it is a best practice to use the torch.no_grad() context manager, as shown below. This tells PyTorch that it doesn’t need to keep track of the gradients, which can result in significant savings in memory and computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1123f4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0890, -0.0484,  0.2022],\n",
      "        [ 0.0577, -0.0256,  0.2039],\n",
      "        [ 0.0426, -0.0311,  0.1928],\n",
      "        [ 0.0904, -0.0504,  0.1904],\n",
      "        [ 0.0565, -0.0335,  0.2270],\n",
      "        [ 0.0378, -0.0475,  0.2277],\n",
      "        [ 0.0914, -0.0816,  0.2008],\n",
      "        [ 0.0075, -0.0024,  0.2608],\n",
      "        [ 0.0761, -0.0527,  0.1947],\n",
      "        [ 0.0737, -0.0323,  0.1963]])\n",
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # don't keep the compute graph in memory\n",
    "    X_tens = torch.rand((10, 50))\n",
    "    out = model(X_tens)\n",
    "    print(out)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15b64d",
   "metadata": {},
   "source": [
    "## 6. Setting up Efficient data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59083f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://sebastianraschka.com/images/teaching/pytorch-1h/figure_10.webp\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# overall idea behind data loading in Pytorch\n",
    "\n",
    "display(Image(url = 'https://sebastianraschka.com/images/teaching/pytorch-1h/figure_10.webp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64500bb",
   "metadata": {},
   "source": [
    "Pytorch implements a ```Dataset``` and ```DataLoader``` class. The Dataset class is used to instantiate objects that define how each data record is loaded. The Dataloader handles how the data is shuffled and assembled into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57113e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create a dataset\n",
    "\n",
    "X_train = torch.tensor([\n",
    "    [-1.2, 3.1],\n",
    "    [-0.9, 2.9],\n",
    "    [-0.5, 2.6],\n",
    "    [2.3, -1.1],\n",
    "    [2.7, -1.5]\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0, 0, 0, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91c910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor([\n",
    "    [-0.8, 2.8],\n",
    "    [2.6, -1.6],\n",
    "])\n",
    "\n",
    "y_test = torch.tensor([0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "583cbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a custom dataset class. \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        one_x = self.features[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_x, one_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e40843a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(X_train, y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b909dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use Pytorch DataLoader class to sample from it\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_ds, \n",
    "    batch_size= 2,\n",
    "    shuffle=True,\n",
    "    num_workers =0 # what's this argument? # parallelism used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31e7d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b4b0e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:  tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 2:  tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 3:  tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# iteration over Dataloader works quite similarly\n",
    "\n",
    "for idx, (X, y) in enumerate(train_loader):\n",
    "    print(f'Batch {idx + 1}: ', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf893f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:  tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "Batch 2:  tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "Batch 3:  tensor([[ 2.7000, -1.5000]]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# second iter is not the same for the DNN to have a different sequence of learning\n",
    "\n",
    "for idx, (X, y) in enumerate(train_loader):\n",
    "    print(f'Batch {idx + 1}: ', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5b26d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that the last batch can have mismatching data samples given the unevenness of data \n",
    "# entries to batch_size, therefore it's recommended to drop the last batch\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle= True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a419c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-0.9000,  2.9000],\n",
      "        [ 2.3000, -1.1000]]) tensor([0, 1])\n",
      "Batch 2: tensor([[ 2.7000, -1.5000],\n",
      "        [-0.5000,  2.6000]]) tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07b08f",
   "metadata": {},
   "source": [
    "## 7. A Typical Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b138f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
      "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
      "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
      "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
      "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
      "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n",
      "tensor([[ 2.8569, -4.1618],\n",
      "        [ 2.5382, -3.7548],\n",
      "        [ 2.0944, -3.1820],\n",
      "        [-1.4814,  1.4816],\n",
      "        [-1.7176,  1.7342]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_outputs=2) # instantiating the model\n",
    "print(model)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5) # instantiating the optimizer we are using\n",
    "\n",
    "num_epochs = 3 # no of training over the full batch that we are doing\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train() # set in training mode\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels) # Loss function\n",
    "\n",
    "        optimizer.zero_grad() # clean the previous results\n",
    "        loss.backward() # compute the gradients \n",
    "        optimizer.step() # use the optimizer to step along the gradients\n",
    "\n",
    "        ### LOGGING\n",
    "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
    "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
    "              f\" | Train/Val Loss: {loss:.2f}\")\n",
    "\n",
    "    model.eval() # eval mode\n",
    "    # Optional model evaluation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_train)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800cffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9991,     0.0009],\n",
      "        [    0.9982,     0.0018],\n",
      "        [    0.9949,     0.0051],\n",
      "        [    0.0491,     0.9509],\n",
      "        [    0.0307,     0.9693]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False) #what's scimode? (just print formatting I guess)\n",
    "probas = torch.softmax(outputs, dim=1)\n",
    "print(probas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e2364aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim = 1) #find the max index along each dim 1 (which is the col dimension)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90167b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb16ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "15e09b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.sum, we can count the number of correct predictions as follows:\n",
    "\n",
    "torch.sum(predictions == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77c3e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generalize the computationa of the prediciton accuracy, we implement\n",
    "\n",
    "def compute_accuracy(model, train_loader):\n",
    "\n",
    "    # set in eval model\n",
    "    model = model.eval()\n",
    "    correct = 0.0\n",
    "    total_examples = 0.0\n",
    "    \n",
    "    for idx, (features, labels) in enumerate(train_loader):\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim = 1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_examples += len(compare)\n",
    "\n",
    "    return (correct / total_examples).item() #getting the values from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08bbff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = compute_accuracy(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f18c7ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d14de5",
   "metadata": {},
   "source": [
    "## 8. Saving and Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1594802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recommended way to save and load models in PyTorch\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4bec0d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),  'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1021b1",
   "metadata": {},
   "source": [
    "The model's ```state_dict``` is a Python dictionary object that maps each layer in the model to its trainable parameters (weights and biases). Note that \"model.pth\" is an arbitrary filename for the model file saved to disk. We can give it any name and file ending we like; however, .pth and .pt are the most common conventions.\n",
    "\n",
    "Once we saved the model, we can restore it from disk as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db20491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(2, 2) # needs to match the original model exactly\n",
    "model.load_state_dict(torch.load('model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b8929ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = NeuralNetwork(2,2)\n",
    "model2.load_state_dict(torch.load('model.pkl', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d2cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
